---
title: multi-random-data-generator
date: 2020-04-13 16:48:59
categories:
---


> 如何快速生成大量的随机测试数据，比如10G的测试文件

单进程，实时写入

1000W => 100s

单进程  不写入只运行逻辑 
1000W => 0.5s

单进程，output_buffering=4096 
1000w=>63s


随机算法   未优化
	|
缓存			写入时先写入缓存区
	|
写入文件		刷新缓存


最后稳定的方法在

运行1亿的数据生产需要13s，写文件需要3s左右

40亿的数据采用单进程大概需要 15分钟(存储跑满了未实际执行，跑到18亿数据大概18G) 
cpu 消耗在20-30左右


最终考虑方案

多进程+刷新缓存写文件


---
php yeild  //本质上并不能减少cpu的计算  最多优化的点在于 在写文件的期间，cpu能继续计算随机值写到内存

