---
title: 跑大量脚本数据
categories: 实践
date: 2018-11-14 15:20:36
---


1 文件转存可以一次读取，避免读压力。oom,后续业务处理错误不必再次读库
2 文件转存可以后续拆分成多任务跑
3 文件转存可以用linux 去重
4 先处理容易出错需要清库的业务
5 转存成文件可以根据处理的行数设置断点续跑
6 除了批量处理，单个处理的逻辑也需要。处理单个异常
7 运行日志很重要,勿删

案例:
10G日志 100个节点的机器需要跑

思路:
10G的日志，加载到数据库或者一次性读取都比较消耗内存和时间
1 将日志按大小成为1000个小文件
2 起100个任务，这里的想法是让每个节点都并行执行，如果节点过多，比如1000各节点不适合开启这么多进程，可以将节点划分成100个组
3 每组节点一个进程遍历所有的日志小文件

tips:
1 跑的时候难免遇到异常，内存溢出，进程异常停止，日志很重要，代码设置能从断点续跑 [时间|排序|增量id|行数]
2 总体思路是拆分成小文件，减少单次加载时间和内存  多任务处理让每个节点并发执行